<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,算法,分类,回归," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="做决定时，大脑中可能有这样的一个思考过程：

这样“精确”的逻辑可能是经历了很多事情才得到的。决策树也类似这个过程：

在样本上，通过精确地划分，形成这样树形的决策逻辑。

存在两种类型的节点：

内部节点：条件或者阈值，决定下一步应该去哪个子树
叶子节点：类型或者预测值

可以理解为：从上到下，通过内部节点将可能性空间不断细分，最终到达一个目标状态（叶子节点）。
基础知识选择哪些维度以及如何划分">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树">
<meta property="og:url" content="http://yoursite.com/2017/02/07/decision-tree/index.html">
<meta property="og:site_name" content="wsztrush">
<meta property="og:description" content="做决定时，大脑中可能有这样的一个思考过程：

这样“精确”的逻辑可能是经历了很多事情才得到的。决策树也类似这个过程：

在样本上，通过精确地划分，形成这样树形的决策逻辑。

存在两种类型的节点：

内部节点：条件或者阈值，决定下一步应该去哪个子树
叶子节点：类型或者预测值

可以理解为：从上到下，通过内部节点将可能性空间不断细分，最终到达一个目标状态（叶子节点）。
基础知识选择哪些维度以及如何划分">
<meta property="og:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/3314af47a35f930ae15d7f88f4b740c9/image.png">
<meta property="og:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/ec99081729eed6a5c8cc98e0853851ae/medium.jpg">
<meta property="og:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/2046c1f2b077a9a9d174c3e52a8377be/image.png">
<meta property="og:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/034c6ec4957449176da3b94cb6ddd7f0/a.png">
<meta property="og:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/5f317c1d7339ac9e69deab6465d8ffb0/image.png">
<meta property="og:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/4e3dace9071d73c0c5f3c6d693dbc4e8/image.png">
<meta property="og:updated_time" content="2017-03-24T00:33:58.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="决策树">
<meta name="twitter:description" content="做决定时，大脑中可能有这样的一个思考过程：

这样“精确”的逻辑可能是经历了很多事情才得到的。决策树也类似这个过程：

在样本上，通过精确地划分，形成这样树形的决策逻辑。

存在两种类型的节点：

内部节点：条件或者阈值，决定下一步应该去哪个子树
叶子节点：类型或者预测值

可以理解为：从上到下，通过内部节点将可能性空间不断细分，最终到达一个目标状态（叶子节点）。
基础知识选择哪些维度以及如何划分">
<meta name="twitter:image" content="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/3314af47a35f930ae15d7f88f4b740c9/image.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'dc4364f27034e113a6c150023a648d49',
      author: 'wsztRush'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/2017/02/07/decision-tree/"/>


  <title> 决策树 | wsztrush </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-CN">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?ab1b083818fdf7317d4a77e34fe07f4c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">wsztrush</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">now or never!!!</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                决策树
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-07T07:18:24+08:00" content="2017-02-07">
              2017-02-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/02/07/decision-tree/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/02/07/decision-tree/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>做决定时，大脑中可能有这样的一个思考过程：</p>
<p><img src="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/3314af47a35f930ae15d7f88f4b740c9/image.png" alt=""></p>
<p>这样“精确”的逻辑可能是经历了很多事情才得到的。决策树也类似这个过程：</p>
<blockquote>
<p>在样本上，通过精确地划分，形成这样<font color="red">树形</font>的决策逻辑。</p>
</blockquote>
<p>存在两种类型的节点：</p>
<ul>
<li>内部节点：条件或者阈值，决定下一步应该去哪个子树</li>
<li>叶子节点：类型或者预测值</li>
</ul>
<p>可以理解为：从上到下，通过内部节点将可能性空间不断细分，最终到达一个目标状态（叶子节点）。</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>选择哪些维度以及如何划分是决策树的核心，也是最难的，需要一些知识准备。</p>
<h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><p>对一片文章的评价可能是信息量很大，也可能是废话连篇。那么：</p>
<blockquote>
<p>能否量化信息的多少？</p>
</blockquote>
<p>什么样的话是废话？</p>
<blockquote>
<p>原来确定的事情，再说一遍就是废话，比如：太阳今天会从东边升起！</p>
</blockquote>
<p>什么样的话信息量比较大？</p>
<blockquote>
<p>原来不确定的事情，再说遍就比较确定了，比如：今天某个股票的财报很好，明天股票会大涨！</p>
</blockquote>
<p><strong>概率发生的变化越大（从无序到有序），信息量也就越大！</strong>而且信息量的多少应该满足：</p>
<ul>
<li>非负</li>
<li>可加：f(xy)=f(x)+f(y)</li>
<li>连续</li>
<li>递减：概率越小，信息量越大</li>
</ul>
<p>满足这些性质的函数只有：</p>
<p>$$<br>-log(x)<br>$$</p>
<p>而信息论祖师爷<strong>Shannon</strong>搞出来的信息熵的含义是：</p>
<blockquote>
<p>系统中所含有的平均信息量的大小，或者是说，描述一个系统需要的最小空间。</p>
</blockquote>
<p>于是，对于概率事件$(A_1,A_2,…,A_n)$，并且各事件对应的概率为$(p_1,p_2,…,p_n)$，则其信息熵为：</p>
<p>$$<br>H(X) = -\sum p_i \times log(p_i)<br>$$</p>
<p>熵函数图形如下：</p>
<p><img src="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/ec99081729eed6a5c8cc98e0853851ae/medium.jpg" alt="medium"></p>
<h2 id="多维度的信息熵"><a href="#多维度的信息熵" class="headerlink" title="多维度的信息熵"></a>多维度的信息熵</h2><p>当系统中有两个维度时，其<font color="red">联合熵</font>为：</p>
<p>$$<br>H(X,Y) = \sum_i \sum_j - p(x_i, y_j) \times log(p(x_i, y_j))<br>$$</p>
<p>显然，当$X$、$Y$<font color="red">不相关</font>时有：</p>
<p>$$<br>H(X,Y) = H(X) + H(Y)<br>$$</p>
<p>并且，当向系统中引入新的维度以后，信息熵总数增加的：</p>
<p>$$<br>H(X,Y) \geqslant H(X) \ \ \ \  H(X,Y) \geqslant H(Y)<br>$$</p>
<p>当某个维度（条件）的值固定（已知）时，其他维度的熵为<font color="red">条件熵</font>：</p>
<p>$$<br>H(Y|X) = \sum p(x_i) \times H(Y|x_i) = H(X,Y) - H(X)<br>$$</p>
<p>两个维度相关的话，说明他们之间有公共的信息（<font color="red">互信息</font>）：</p>
<p>$$<br>\begin{align}<br>I(X;Y) &amp; = H(X) - H(X|Y) \\<br> &amp; = H(Y) - H(Y|X) \\<br> &amp; = H(X) + H(Y) - H(X,Y) \\<br> &amp; = H(X,Y) - H(X|Y) - H(Y|X) \\<br> &amp; = \sum \sum p(x,y) \times log \left ( \frac{p(x,y)}{p(x)\times p(y)}\right )<br>\end{align}<br>$$</p>
<h2 id="信息增益和信息增益比"><a href="#信息增益和信息增益比" class="headerlink" title="信息增益和信息增益比"></a>信息增益和信息增益比</h2><p>互信息从另外一个角度理解：</p>
<blockquote>
<p>当某个维度固定之后，对其他维度的信息熵的影响多少。</p>
</blockquote>
<p>此时的说法就是<font color="red">信息增益</font>了。直观上<strong>信息增益越大越相关</strong>，但是缺点很明显：</p>
<blockquote>
<p>不同维度的基数不一样，大家的起跑线也就不同了。</p>
</blockquote>
<p>可以用通过影响量的比例（<font color="red">信息增益比</font>）来衡量效果的好坏：</p>
<p>$$<br>I_r = \frac{I(X,Y)}{I(X)}<br>$$</p>
<h2 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h2><p>劳伦茨曲线是由经济学家劳伦茨提出用来描述收入分配：</p>
<p><img src="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/2046c1f2b077a9a9d174c3e52a8377be/image.png" alt="image"></p>
<p>其中：</p>
<ul>
<li>横轴为人口累计（人口对应的收入从低到高）</li>
<li>纵轴为收入累计</li>
</ul>
<p>阿尔伯特·赫希曼在此基础上提出基尼系数，用来描述是否平均（面积的比例，比例越大越不平均）：</p>
<p>$$<br>Gini = \frac{A}{A+B}<br>$$</p>
<p>对一个数据集上的概率，$Gini$系数计算方式如下：</p>
<p>$$<br>Gini = 1 - \sum p_i^2 = \sum p_i \times (1-p_i)<br>$$</p>
<p>基尼系数越大系统越混乱（不确定），貌似和经济学中的概念不大一样，反而看$y=x \times (1-x)$的图形更好理解一些（先留个坑）：</p>
<p><img src="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/034c6ec4957449176da3b94cb6ddd7f0/a.png" alt="a"></p>
<h1 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h1><p>不同决策树算法的流程是相似的：</p>
<ul>
<li>生成树模型</li>
<li>剪枝</li>
<li>预测：回归/分类，也就是模型的使用</li>
</ul>
<p>下面依次来看！</p>
<h2 id="生成树"><a href="#生成树" class="headerlink" title="生成树"></a>生成树</h2><p>总体来说是希望在细分样本的过程中，不确定性不断地降低，不同衡量的准则产生了不同的算法。</p>
<h3 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h3><p>衡量标准为信息增益：</p>
<blockquote>
<p>每次选择出来的维度，信息增益越大越好。</p>
</blockquote>
<p><strong>举个栗子</strong>：</p>
<table>
<thead>
<tr>
<th>outlook</th>
<th>temperature</th>
<th>humidity</th>
<th>windy</th>
<th>class</th>
</tr>
</thead>
<tbody>
<tr>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>N</td>
</tr>
<tr>
<td>sunny</td>
<td>hot</td>
<td>high</td>
<td>true</td>
<td>N</td>
</tr>
<tr>
<td>overcast</td>
<td>hot</td>
<td>high</td>
<td>false</td>
<td>P</td>
</tr>
<tr>
<td>rain</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>P</td>
</tr>
<tr>
<td>rain</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>P</td>
</tr>
<tr>
<td>rain</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>N</td>
</tr>
<tr>
<td>overcast</td>
<td>cool</td>
<td>normal</td>
<td>true</td>
<td>P</td>
</tr>
<tr>
<td>sunny</td>
<td>mild</td>
<td>high</td>
<td>false</td>
<td>N</td>
</tr>
<tr>
<td>sunny</td>
<td>cool</td>
<td>normal</td>
<td>false</td>
<td>P</td>
</tr>
<tr>
<td>rain</td>
<td>mild</td>
<td>normal</td>
<td>false</td>
<td>P </td>
</tr>
<tr>
<td>sunny</td>
<td>mild</td>
<td>normal</td>
<td>true</td>
<td>P </td>
</tr>
<tr>
<td>overcast</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>P </td>
</tr>
<tr>
<td>overcast</td>
<td>hot</td>
<td>normal</td>
<td>false</td>
<td>P </td>
</tr>
<tr>
<td>rain</td>
<td>mild</td>
<td>high</td>
<td>true</td>
<td>N</td>
</tr>
</tbody>
</table>
<p>于是有$p_n=5/14$,$p_p=9/14$，整体的信息熵为：</p>
<p>$$<br>-\frac{5}{14}log(\frac{5}{14})-\frac{9}{14}log(\frac{9}{14})=0.94<br>$$</p>
<p>当$outlook=sunny$时，$p_n=3/5$,$p_p=2/5$，得到信息熵为：</p>
<p>$$<br>-\frac{3}{5}log(\frac{3}{5})-\frac{2}{5}log(\frac{2}{5})=0.971<br>$$</p>
<p>同样可以得到$outlook=overcast$时的信息熵为0,$outlook=rain$时为0.971,于是此时的信息增益为：</p>
<p>$$<br>gain(outlook)=0.940-(\frac{5}{14} \times 0.971+\frac{4}{14} \times 0+\frac{5}{14} \times 0.971)=0.246<br>$$</p>
<p>同样的方法可以得到：</p>
<p>$$<br>\begin{align}<br>gain(temperature) &amp;= 0.029 \\<br>gain(humidity) &amp;= 0.151 \\<br>gain(windy) &amp;= 0.048<br>\end{align}<br>$$</p>
<p>这样第一层选择$outlook$作为条件效果最好，后面各层可以依次进行选择。</p>
<p><strong>代码实现</strong>（勉强先看吧- -!）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> math</div><div class="line"></div><div class="line"><span class="comment"># 计算目标分类的信息熵</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_class_entropy</span><span class="params">(data)</span>:</span></div><div class="line">    n_num = p_num = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">if</span> record[<span class="number">-1</span>] == <span class="string">'N'</span>:</div><div class="line">            n_num += <span class="number">1</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            p_num += <span class="number">1</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> calc_entropy(p_num, len(data)) + calc_entropy(n_num, len(data))</div><div class="line"></div><div class="line"><span class="comment"># 计算信息熵</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_entropy</span><span class="params">(p, t)</span>:</span></div><div class="line">    <span class="keyword">if</span> p == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> -(p / t) * math.log2(p / t)</div><div class="line"></div><div class="line"><span class="comment"># 计算按照某列来分类得到的信息熵</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_column_score</span><span class="params">(data, column)</span>:</span></div><div class="line">    column_key_count = &#123;&#125;</div><div class="line">    column_key_record = &#123;&#125;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> data:</div><div class="line">        column_key = record[column]</div><div class="line">        column_key_count[column_key] = column_key_count[column_key] + <span class="number">1</span> <span class="keyword">if</span> column_key <span class="keyword">in</span> column_key_count <span class="keyword">else</span> <span class="number">1</span></div><div class="line"></div><div class="line">        column_key_record[column_key] = column_key_record[column_key] <span class="keyword">if</span> column_key <span class="keyword">in</span> column_key_record <span class="keyword">else</span> []</div><div class="line">        column_key_record[column_key].append(record)</div><div class="line"></div><div class="line">    ret = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> column_key_count:</div><div class="line">        ret += column_key_count[key] / len(data) * calc_class_entropy(column_key_record[key])</div><div class="line"></div><div class="line">    <span class="keyword">return</span> ret</div><div class="line"></div><div class="line"><span class="comment"># 处理一层</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(data, parent_column, parent_column_value)</span>:</span></div><div class="line">    min_entropy = calc_class_entropy(data)</div><div class="line">    target_column = <span class="number">-1</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> range(len(data[<span class="number">0</span>]) - <span class="number">1</span>):</div><div class="line">        tmp = calc_column_score(data, column)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> tmp &lt; min_entropy:</div><div class="line">            min_entropy = tmp</div><div class="line">            target_column = column</div><div class="line"></div><div class="line">    print(parent_column, parent_column_value, target_column)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> min_entropy == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span></div><div class="line"></div><div class="line">    sub_data = &#123;&#125;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> data:</div><div class="line">        key = record[target_column]</div><div class="line"></div><div class="line">        <span class="keyword">del</span> record[target_column]</div><div class="line"></div><div class="line">        sub_data[key] = sub_data[key] <span class="keyword">if</span> key <span class="keyword">in</span> sub_data <span class="keyword">else</span> []</div><div class="line">        sub_data[key].append(record)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> sub_data:</div><div class="line">        process(sub_data[key], target_column, key)</div><div class="line"></div><div class="line"><span class="comment"># 主函数</span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    fp = open(<span class="string">"./data.txt"</span>, <span class="string">"r"</span>)</div><div class="line"></div><div class="line">    data = []</div><div class="line"></div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fp:</div><div class="line">        data.append(line.strip().split(<span class="string">','</span>)[:])</div><div class="line"></div><div class="line">    process(data, <span class="number">0</span>, <span class="string">"#"</span>)</div></pre></td></tr></table></figure>
<h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h3><p>针对ID3的缺点：</p>
<ul>
<li>倾向选择细分最多的维度</li>
<li>不能处理连续数据</li>
</ul>
<p>提出了新的C4.5算法，使用<strong>信息增益率代替信息增益</strong>解决了第一点。离散化的思路是：</p>
<blockquote>
<p>选择阈值，将连续型的数据划分到不同的区间。</p>
</blockquote>
<p>假如有$N$个不同的连续值，可选的阈值有$N-1$种，计算量较大，一种优化方法是：</p>
<blockquote>
<p>将连续值排序，只有在Class发生变化的时候才考虑作为阈值。</p>
</blockquote>
<p><strong>举个栗子</strong>：</p>
<p><img src="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/5f317c1d7339ac9e69deab6465d8ffb0/image.png" alt="image"></p>
<p>原来需要考虑13种可能，而优化后只需要7种。</p>
<h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h3><p>CART是一棵二叉树，可回归可分类，划分子树选择的标准不同：</p>
<ul>
<li>分类：基尼系数</li>
<li>回归：方差</li>
</ul>
<p>补充方差计算方式：</p>
<p>$$<br>T = min \left [min \sum (y_i-c_1)^2 + min \sum(y_j-c_2)^2 \right ] \\<br>c_k = \frac{\sum y_i}{N_k}<br>$$</p>
<p>在分类树中，用基尼系数代替了信息熵，其他貌似也没什么特别的，举个例子来说明：</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>体温</th>
<th>表面</th>
<th>胎生</th>
<th>产蛋</th>
<th>能飞</th>
<th>水生</th>
<th>有腿</th>
<th>冬眠</th>
<th>类标记</th>
</tr>
</thead>
<tbody>
<tr>
<td>人</td>
<td>恒温</td>
<td>毛发</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>哺乳类</td>
</tr>
<tr>
<td>巨蟒</td>
<td>冷血</td>
<td>鳞片</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>爬行类</td>
</tr>
<tr>
<td>鲑鱼</td>
<td>冷血</td>
<td>鳞片</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>鱼类</td>
</tr>
<tr>
<td>鲸</td>
<td>恒温</td>
<td>毛发</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>哺乳类</td>
</tr>
<tr>
<td>蛙</td>
<td>冷血</td>
<td>无</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>有时</td>
<td>是</td>
<td>是</td>
<td>两栖类</td>
</tr>
<tr>
<td>巨蜥</td>
<td>冷血</td>
<td>鳞片</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>爬行类</td>
</tr>
<tr>
<td>鸽子</td>
<td>恒温</td>
<td>毛发</td>
<td>否</td>
<td>是</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>鸟类</td>
</tr>
<tr>
<td>蝙蝠</td>
<td>恒温</td>
<td>毛发</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>哺乳类</td>
</tr>
<tr>
<td>猫</td>
<td>恒温</td>
<td>皮</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>哺乳类</td>
</tr>
<tr>
<td>豹纹鲨</td>
<td>冷血</td>
<td>鳞片</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>鱼类</td>
</tr>
<tr>
<td>海龟</td>
<td>冷血</td>
<td>鳞片</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>有时</td>
<td>是</td>
<td>否</td>
<td>爬行类</td>
</tr>
<tr>
<td>豪猪</td>
<td>恒温</td>
<td>刚毛</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>是</td>
<td>哺乳类</td>
</tr>
<tr>
<td>猫头鹰</td>
<td>恒温</td>
<td>毛发</td>
<td>否</td>
<td>是</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>鸟类</td>
</tr>
<tr>
<td>鳗</td>
<td>冷血</td>
<td>鳞片</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>否</td>
<td>鱼类</td>
</tr>
<tr>
<td>蝾螈</td>
<td>冷血</td>
<td>无</td>
<td>否</td>
<td>是</td>
<td>否</td>
<td>有时</td>
<td>是</td>
<td>是</td>
<td>两栖类</td>
</tr>
</tbody>
</table>
<p>对于体温为恒温的样本中，有5个哺乳类、2个鸟类，于是得到：</p>
<p>$$<br>Gini = 1 - (\frac{5}{7})^2 - (\frac{2}{7})^2 = \frac{20}{49}<br>$$</p>
<p>对于体温为非恒温的样本，有3个爬行类、3个鱼类、2个两栖类，于是得到：</p>
<p>$$<br>Gini = 1 - (\frac{3}{8})^2 - (\frac{3}{8})^2 - (\frac{2}{8})^2 = \frac{42}{64}<br>$$</p>
<p>于是得到根据体温划分的整体基尼系数为：</p>
<p>$$<br>Gini = \frac{7}{15} \times \frac{20}{49} + \frac{8}{15} \times \frac{42}{64}= 0.540<br>$$</p>
<p>继续计算其他切分点和维度，在所有结果中选$Gini$系数最小的。</p>
<h2 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h2><p>将树无限的细分下去，会导致严重的过拟合，对于Tree-Based算法剪枝比生成还重要。两种剪枝方法:</p>
<ul>
<li>前剪枝：在生成的过程中根据一些指标决定不再分裂</li>
<li>后剪枝：在生成的树上，裁剪掉一些子树</li>
</ul>
<p>前剪枝的规则一般较简单、粗暴，比如深度、阈值等，重点关注后剪枝。</p>
<h3 id="Reduced-Error-Pruning（错误率降低）"><a href="#Reduced-Error-Pruning（错误率降低）" class="headerlink" title="Reduced-Error Pruning（错误率降低）"></a>Reduced-Error Pruning（错误率降低）</h3><p>既然过拟合导致错误率升高，那就从错误率入手：</p>
<blockquote>
<p>找一组新数据，想办法来修剪模型（降低），来降低错误率。</p>
</blockquote>
<p>依次尝试内部节点：</p>
<ol>
<li>删除子节点</li>
<li>计算本节点类型</li>
<li>验证新树错误率，如果降低则保留修改</li>
</ol>
<p>循环执行，直到找不到可删的节点。</p>
<h3 id="Pessimistic-Error-Pruning（悲观）"><a href="#Pessimistic-Error-Pruning（悲观）" class="headerlink" title="Pessimistic-Error Pruning（悲观）"></a>Pessimistic-Error Pruning（悲观）</h3><p>没有新的数据的话怎么办？<strong>REP</strong>本身是否可能过拟合？换种思路：</p>
<blockquote>
<p>既然过拟合是因为“太精确”了，那么在样本上不那么精确的话可能泛化能力会强一些。</p>
</blockquote>
<p>这里要讲平衡：<strong>要放开也不能放得太开，不然反而不精确</strong>，这里可以用统计概念<font color="red">置信区间</font>：</p>
<blockquote>
<p>当给出某个估计值的90%置信区间为【a,b】时,可以理解为我们有90%的信心可以说样本的平均值介于a到b之间,而发生错误的概率为10%.</p>
</blockquote>
<p>知道样本均值(M)和标准差(ST)时：</p>
<p>$$<br>a = M - n \times ST \ \ \ \ b = M + n \times ST<br>$$</p>
<p>假设误差符合二项分布，那么判断是否需要剪枝的条件为（其中$\frac{1}{2}$为修正因子）：</p>
<p>$$<br>\begin{align}<br>condition\ \ \ &amp; e’(t) \leqslant e’(T_t) + S_e(e’(T_t)) \\<br>&amp; e’(t)=\left [ e(t) + \frac{1}{2} \right ] \\<br>&amp; e’(T_t) = \sum e(i) + N_t \times \frac{1}{2} \\<br>&amp; S_e(e’(T_t)) = \sqrt{N_t \times \frac{e’(t)}{N_t} \times \left (1 - \frac{e’(t)}{N_t}\right )}<br>\end{align}<br>$$</p>
<p>看个例子:</p>
<p><img src="http://git.cn-hangzhou.oss.aliyun-inc.com/uploads/tianchi.gzt/note/4e3dace9071d73c0c5f3c6d693dbc4e8/image.png" alt="image"></p>
<p>计算得到：</p>
<p>$$<br>\begin{align}<br>&amp; e’(t)=\left [ e(t) + \frac{1}{2} \right ]  = 8.5 \\<br>&amp; e’(T_t) = \sum e(i) + N_t \times \frac{1}{2} = 4 + 1 + 1 + 3 \times \frac{1}{2} = 7.5 \\<br>&amp; S_e(e’(T_t)) = \sqrt{N_t \times \frac{e’(t)}{N_t} \times \left (1 - \frac{e’(t)}{N_t}\right )}  = \sqrt{3 \times \frac{7.5}{18} \times (1-\frac{7.5}{18})} = 2.09<br>\end{align}<br>$$</p>
<p>于是得到：</p>
<p>$$<br>e’(t) \leqslant e’(T_t) + S_e(e’(T_t))<br>$$</p>
<p>该子树可以被剪掉。</p>
<h3 id="Cost-Complexity-Pruning（代价复杂度）"><a href="#Cost-Complexity-Pruning（代价复杂度）" class="headerlink" title="Cost-Complexity Pruning（代价复杂度）"></a>Cost-Complexity Pruning（代价复杂度）</h3><p><strong>REP</strong>和<strong>PEP</strong>都是站在单个节点上判断要不要剪，CCP的思路为：</p>
<blockquote>
<p>递归生成一组剪完的子树，然后在通过验证数据挑最优子树。</p>
</blockquote>
<p>对于当前子树$T_i$,计算内部节点误差增益，假设样本数为$C_{all}$：</p>
<p>$$<br>\begin{align}<br>&amp; R(t) = \frac{e_t}{C_t} \times \frac{N_t}{C_{all}} \\<br>&amp; R(T) = \sum \frac{e_i}{C_i} \times \frac{C_i}{C_{all}} \\<br>&amp; \alpha = \frac{R(t) - R(T)}{N_t - 1}<br>\end{align}<br>$$</p>
<p>对于上面的例子，在$C_{all} = 40$时：</p>
<p>$$<br>\begin{align}<br>&amp; R(t) = \frac{e_t}{C_t} \times \frac{C_t}{N_{all}} = \frac{8}{18} \times \frac{18}{40} = \frac{8}{40} \\<br>&amp; R(T) = \sum \frac{e_i}{C_i} \times \frac{C_i}{C_{all}} = \frac{4}{9} \times \frac{9}{40} + \frac{1}{6} \times \frac{6}{40} + \frac{1}{3} \times \frac{3}{40} = \frac{6}{40} \\<br>&amp; \alpha = \frac{R(t) - R(T)}{N_t - 1} = \frac{\frac{8}{40} - \frac{6}{40}}{3 - 1} = \frac{1}{40}<br>\end{align}<br>$$</p>
<p>从$T_i$中剪去$\alpha$最小的得到$T_{i+1}$，循环执行得到$ T_0,…,T_n $，利用验证数据从中选择最优子树即可。</p>
<h1 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h1><p>使用sklearn中决策树做分类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span></div></pre></td></tr></table></figure>
<p>回归：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span></div></pre></td></tr></table></figure>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="http://ccckmit.wikidot.com/st:mutualinformation" target="_blank" rel="external">http://ccckmit.wikidot.com/st:mutualinformation</a></li>
<li><a href="http://www.cnblogs.com/yonghao/p/5135386.html" target="_blank" rel="external">http://www.cnblogs.com/yonghao/p/5135386.html</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_4e4dec6c0101fdz6.html" target="_blank" rel="external">http://blog.sina.com.cn/s/blog_4e4dec6c0101fdz6.html</a></li>
<li><a href="http://www.cnblogs.com/yonghao/p/5064996.html" target="_blank" rel="external">http://www.cnblogs.com/yonghao/p/5064996.html</a></li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag">#机器学习</a>
          
            <a href="/tags/算法/" rel="tag">#算法</a>
          
            <a href="/tags/分类/" rel="tag">#分类</a>
          
            <a href="/tags/回归/" rel="tag">#回归</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/01/07/how-to-communicate/" rel="next" title="如何沟通">
                <i class="fa fa-chevron-left"></i> 如何沟通
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/03/09/landor/" rel="prev" title="生与死">
                生与死 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="wsztrush" />
          <p class="site-author-name" itemprop="name">wsztrush</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">15</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#基础知识"><span class="nav-number">1.</span> <span class="nav-text">基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#信息熵"><span class="nav-number">1.1.</span> <span class="nav-text">信息熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多维度的信息熵"><span class="nav-number">1.2.</span> <span class="nav-text">多维度的信息熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#信息增益和信息增益比"><span class="nav-number">1.3.</span> <span class="nav-text">信息增益和信息增益比</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基尼系数"><span class="nav-number">1.4.</span> <span class="nav-text">基尼系数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#算法流程"><span class="nav-number">2.</span> <span class="nav-text">算法流程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#生成树"><span class="nav-number">2.1.</span> <span class="nav-text">生成树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ID3"><span class="nav-number">2.1.1.</span> <span class="nav-text">ID3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C4-5"><span class="nav-number">2.1.2.</span> <span class="nav-text">C4.5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART"><span class="nav-number">2.1.3.</span> <span class="nav-text">CART</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#剪枝"><span class="nav-number">2.2.</span> <span class="nav-text">剪枝</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reduced-Error-Pruning（错误率降低）"><span class="nav-number">2.2.1.</span> <span class="nav-text">Reduced-Error Pruning（错误率降低）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pessimistic-Error-Pruning（悲观）"><span class="nav-number">2.2.2.</span> <span class="nav-text">Pessimistic-Error Pruning（悲观）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Cost-Complexity-Pruning（代价复杂度）"><span class="nav-number">2.2.3.</span> <span class="nav-text">Cost-Complexity Pruning（代价复杂度）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#工具"><span class="nav-number">3.</span> <span class="nav-text">工具</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#总结"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考"><span class="nav-number">5.</span> <span class="nav-text">参考</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wsztrush</span>
</div>

<!--
<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>


<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

-->

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'wsztrush';
      var disqus_identifier = '2017/02/07/decision-tree/';
      var disqus_title = "决策树";
      var disqus_url = 'http://yoursite.com/2017/02/07/decision-tree/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        // TODO dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        dsq.src = '//a.disquscdn.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        var disqus_config = function () {
            this.page.url = disqus_url;
            this.page.identifier = disqus_identifier;
            this.page.title = disqus_title;
        };
        run_disqus_script('embed.js');
      
    </script>
  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
